{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fc8iHXIVwDwj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***Some parts of the notebook are almost the copy of [ mmta-team course](https://github.com/mmta-team/mmta_fall_2020). Special thanks to mmta-team for making them publicly available. [Original notebook](https://github.com/mmta-team/mmta_fall_2020/blob/master/tasks/01_word_embeddings/task_word_embeddings.ipynb).***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIWqBuEa6j0b",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задача поиска схожих по смыслу предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUkwMPLA6j0g",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Мы будем ранжировать вопросы [StackOverflow](https://stackoverflow.com) на основе семантического векторного представления "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS9FwWNd5a3S",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задача ранжирования(Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdwY9-f75a3T",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* $X$ - множество объектов\n",
    "* $X^l = \\{x_1, x_2, ..., x_l\\}$ - обучающая выборка\n",
    "<br>На обучающей выборке задан порядок между некоторыми элементами, то есть нам известно, что некий объект выборки более релевантный для нас, чем другой:\n",
    "* $i \\prec j$ - порядок пары индексов объектов на выборке $X^l$ c индексами $i$ и $j$\n",
    "### Задача:\n",
    "построить ранжирующую функцию $a$ : $X \\rightarrow R$ такую, что\n",
    "$$i \\prec j \\Rightarrow a(x_i) < a(x_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WG2IGBsh5a3U",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://d25skit2l41vkl.cloudfront.net/wp-content/uploads/2016/12/Featured-Image.jpg\" width=500, height=450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQk_rolFwT_h",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUe1PGXn6j0l",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Будем использовать предобученные векторные представления слов на постах Stack Overflow.<br>\n",
    "[A word2vec model trained on Stack Overflow posts](https://github.com/vefstathiou/SO_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mYkI54Y-rk7a",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://zenodo.org/record/1199620/files/SO_vectors_200.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "O8YJTOYv6j0s",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "wv_embeddings = KeyedVectors.load_word2vec_format(\"SO_vectors_200.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIcT_g-C6j1E",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Как пользоваться этими векторами?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWO5SPDY6j1G",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Посмотрим на примере одного слова, что из себя представляет embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KeSBlQfk6j1J",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 (200,)\n"
     ]
    }
   ],
   "source": [
    "word = 'dog'\n",
    "if word in wv_embeddings:\n",
    "    print(wv_embeddings[word].dtype, wv_embeddings[word].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "T4Eq-D1qxpMJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of words: 1787145\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num of words: {len(wv_embeddings.index_to_key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZT6NTCys6j1Q",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Найдем наиболее близкие слова к слову `dog`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nYwVz0xG6j1U",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# method most_simmilar\n",
    "def most_similar(words:list, embeddings, inclusion=False, print_negative=True):\n",
    "    '''\n",
    "    words: список слов, наличие которых проверяем в векторных представленияx.\n",
    "    embeddings: массив векторных представлений.\n",
    "    inclusion: проверяет входит ли inclusion в Топ-5 близких слов к словам words.\n",
    "    print_negative: выводить или нет на печать отсутствующие слова.\n",
    "    Если да, указывает место в рейтинге вхождений.  \n",
    "    '''\n",
    "    for word in words:\n",
    "        if word in embeddings:\n",
    "            print(f'Слово {word} присутствует в векторных представлениях')\n",
    "            similar = dict(embeddings.most_similar(word))\n",
    "            if inclusion:\n",
    "                try:\n",
    "                    position = sorted(similar.values(), reverse=True).index(similar[inclusion])+1\n",
    "                    if position <= 5:\n",
    "                        print(f'Слово {inclusion} входит в Топ-5 близких слов к слову {word} под номером {position}')\n",
    "                except KeyError:\n",
    "                    print(f'Слово {inclusion} не входит в Топ-5 близких слов к слову {word}')    \n",
    "        else:\n",
    "            if print_negative:\n",
    "                print(f'Слово {word} отсутствует в векторных представлениях')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Проверим, входит ли слово `cat` в топ-5 близких слов к слову `dog`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово dog присутствует в векторных представлениях\n",
      "Слово cat не входит в Топ-5 близких слов к слову dog\n"
     ]
    }
   ],
   "source": [
    "most_similar(['dog'], wv_embeddings, 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Нет, не входит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Проверим ещё, может слово `cats` входит?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово dog присутствует в векторных представлениях\n",
      "Слово cats входит в Топ-5 близких слов к слову dog под номером 4\n"
     ]
    }
   ],
   "source": [
    "most_similar(['dog'], wv_embeddings, 'cats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Да, есть вхождение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Попробуем поменять `cat` и `dog` местами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово cat присутствует в векторных представлениях\n",
      "Слово dog входит в Топ-5 близких слов к слову cat под номером 2\n"
     ]
    }
   ],
   "source": [
    "most_similar(['cat'], wv_embeddings, 'dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Проверим, приведены ли слова в предобученных эмбеддингах к `lower`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово Python отсутствует в векторных представлениях\n",
      "Слово python присутствует в векторных представлениях\n",
      "Слово Apple отсутствует в векторных представлениях\n",
      "Слово apple присутствует в векторных представлениях\n",
      "Слово Internet отсутствует в векторных представлениях\n",
      "Слово internet присутствует в векторных представлениях\n",
      "Слово Microsoft отсутствует в векторных представлениях\n",
      "Слово microsoft присутствует в векторных представлениях\n"
     ]
    }
   ],
   "source": [
    "most_similar(['Python', 'python', 'Apple', 'apple', 'Internet', 'internet', 'Microsoft', 'microsoft'], wv_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Слово `Internet` по правилам английского языка должно быть написано с большой буквы, впрочем как и `Microsoft`. Теперь очевидно, что слова при обучении эмбеддингов были приведены к `lower`. Таким образом имеет смысл в дальнейшем приводить слова к `lower` при их поиске в векторных представлениях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Проверим были ли нормализованы слова перед обучением эмбеддингов, для этого попробуем найти разные формы одного и того же слова в векторных представлениях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово recognised присутствует в векторных представлениях\n",
      "Слово recogniser присутствует в векторных представлениях\n",
      "Слово recognise присутствует в векторных представлениях\n",
      "Слово recognising присутствует в векторных представлениях\n"
     ]
    }
   ],
   "source": [
    "most_similar(['recognised', 'recogniser', 'recognise', 'recognising'], wv_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В векторных представлениях присутствуют различные формы одного и того же слова, поэтому предварительная нормализация слов для создания токенов не обязательна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Проверим наличие `Стоп Слов` в векторных представлениях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopWords = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово ours присутствует в векторных представлениях\n",
      "Слово himself присутствует в векторных представлениях\n",
      "Слово will присутствует в векторных представлениях\n",
      "Слово just присутствует в векторных представлениях\n",
      "Слово now присутствует в векторных представлениях\n",
      "Слово o присутствует в векторных представлениях\n",
      "Слово y присутствует в векторных представлениях\n",
      "Слово ain присутствует в векторных представлениях\n",
      "Слово ma присутствует в векторных представлениях\n",
      "Слово mightn присутствует в векторных представлениях\n",
      "Слово needn присутствует в векторных представлениях\n"
     ]
    }
   ],
   "source": [
    "most_similar(stopWords, wv_embeddings, print_negative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Лишь только малая часть стоп слов присутствует в векторных представлениях, поэтому предварительная фильтрация по листу стоп слов для создания токенов не обязательна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Проверим наличие знаков пунктуации в векторных представлениях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово # присутствует в векторных представлениях\n",
      "Слово + присутствует в векторных представлениях\n",
      "Слово - присутствует в векторных представлениях\n",
      "Слово / присутствует в векторных представлениях\n",
      "Слово \\ присутствует в векторных представлениях\n",
      "Слово _ присутствует в векторных представлениях\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "most_similar(string.punctuation, wv_embeddings, print_negative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В векторных представлениях присутствуют лишь несколько знаков пунктуации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ai48-5vv6j1d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Векторные представления текста\n",
    "\n",
    "Перейдем от векторных представлений отдельных слов к векторным представлениям вопросов, как к **среднему** векторов всех слов в вопросе. Если для какого-то слова нет предобученного вектора, то его нужно пропустить. Если вопрос не содержит ни одного известного слова, то нужно вернуть нулевой вектор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Применим различные типы токенайзеров:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Используем собственный класс токенайзера, основанный на регулярных выражения и возвращающий слова без знаков пунктуации и без применения нормализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EhNuxBJd6j1f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def tokenize(self, text):\n",
    "        return re.findall('\\w+', text)\n",
    "\n",
    "re_tokenizer = MyTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Загрузим библиотечный токенайзер, который помимо слов токенизирует знаки пунктуации, но не применяет нормализацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "wp_tokenizer = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Загрузим ещё один библиотечный токенайзер, который помимо слов токенизирует знаки пунктуации, но применяет нормализацию (лемматизацию)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "class SpacyTokenizer():  \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def tokenize(self, text):\n",
    "        spacy_results = nlp(text)\n",
    "        return [token.lemma_ for token in spacy_results]\n",
    "\n",
    "spacy_tokenizer = SpacyTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# словарь используемых токенайзеров\n",
    "tokenizers = {'RE_tokenizer':re_tokenizer, 'WP_tokenizer':wp_tokenizer, 'Spacy_tokenizer':spacy_tokenizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def question_to_vec(question, embeddings, tokenizer, dim=200):\n",
    "    \"\"\"\n",
    "        question: строка\n",
    "        embeddings: наше векторное представление\n",
    "        tokenizer: токенайзер\n",
    "        dim: размер любого вектора в нашем представлении\n",
    "        return: векторное представление для вопроса\n",
    "    \"\"\" \n",
    "    itr = 0\n",
    "    tokens = tokenizer.tokenize(question.lower())  # приведём к нижнему регистру\n",
    "    q_vector = np.zeros(dim, dtype='float32')\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in embeddings:\n",
    "            q_vector += embeddings[token]\n",
    "            itr += 1\n",
    "    \n",
    "    if itr:\n",
    "        return q_vector / itr  # если есть хоть один эмбеддинг, возвращаем среднее\n",
    "    else:\n",
    "        return q_vector        # если нет, - возвращаем нулевой вектор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5Q_4j7r6j1u",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь у нас есть метод для создания векторного представления любого предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токенайзер: RE_tokenizer, результат: -1.29\n",
      "Токенайзер: WP_tokenizer, результат: -1.29\n",
      "Токенайзер: Spacy_tokenizer, результат: -1.41\n"
     ]
    }
   ],
   "source": [
    "string = 'I love neural networks'\n",
    "\n",
    "for name, tokenizer in tokenizers.items():\n",
    "    string_vector = question_to_vec(string, wv_embeddings, tokenizer)\n",
    "    print(f'Токенайзер: {name}, результат: {string_vector[2]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y60z4t6W6j16",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Оценка близости текстов\n",
    "\n",
    "Представим, что мы используем идеальные векторные представления слов. Тогда косинусное расстояние между дублирующими предложениями должно быть меньше, чем между случайно взятыми предложениями. \n",
    "\n",
    "Сгенерируем для каждого из $N$ вопросов $R$ случайных отрицательных примеров и примешаем к ним также настоящие дубликаты. Для каждого вопроса будем ранжировать с помощью нашей модели $R + 1$ примеров и смотреть на позицию дубликата. Мы хотим, чтобы дубликат был первым в ранжированном списке.\n",
    "\n",
    "#### Hits@K\n",
    "Первой простой метрикой будет количество корректных попаданий для какого-то $K$:\n",
    "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [rank\\_q_i^{'} \\le K],$$\n",
    "* $\\begin{equation*}\n",
    "[x < 0 ] \\equiv \n",
    " \\begin{cases}\n",
    "   1, &x < 0\\\\\n",
    "   0, &x \\geq 0\n",
    " \\end{cases}\n",
    "\\end{equation*}$ - индикаторная функция\n",
    "* $q_i$ - $i$-ый вопрос\n",
    "* $q_i^{'}$ - его дубликат\n",
    "* $rank\\_q_i^{'}$ - позиция дубликата в ранжированном списке ближайших предложений для вопроса $q_i$.\n",
    "\n",
    "#### DCG@K\n",
    "Второй метрикой будет упрощенная DCG метрика, учитывающая порядок элементов в списке путем домножения релевантности элемента на вес равный обратному логарифму номера позиции::\n",
    "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank\\_q_i^{'})}\\cdot[rank\\_q_i^{'} \\le K],$$\n",
    "С такой метрикой модель штрафуется за большой ранк корректного ответа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHCnH-jw6j18",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Максимум `Hits@47 - DCG@1`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Максимум разности двух метрик достигается при максимуме уменьшаемой метрики (`Hits@47`) и минимуме вычитаемой метрики (`DCG@1`). Из определений метрик очевидно, что максимум обоих метрик равен `1` при $rank\\_q_i^{'} = 1$ для каждого из вопросов `N` вне зависимости от `K` (`K` не может быть меньше `1`) . Минимум метрик равен `0` при $rank\\_q_i^{'} > K$ для каждого из вопросов `N`. Если `Hits@47 - DCG@1` взаимосвязаны и относятся к одному примеру, то максимум `Hits@47 - DCG@1` равен `1 - 0 = 1` при $1 < rank\\_q_i^{'} < 48$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tFemBkP6j1-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src='https://hsto.org/files/1c5/edf/dee/1c5edfdeebce4b71a86bdf986d9f88f2.jpg' width=400, height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sUSxk866j1_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Пример оценок\n",
    "\n",
    "Вычислим описанные выше метрики для игрушечного примера. \n",
    "Пусть\n",
    "* $N = 1$, $R = 3$\n",
    "* <font color='green'>\"Что такое python?\"</font> - вопрос $q_1$\n",
    "* <font color='red'>\"Что такое язык python?\"</font> - его дубликат $q_i^{'}$\n",
    "\n",
    "Пусть модель выдала следующий ранжированный список кандидатов:\n",
    "\n",
    "1. \"Как изучить с++?\"\n",
    "2. <font color='red'>\"Что такое язык python?\"</font>\n",
    "3. \"Хочу учить Java\"\n",
    "4. \"Не понимаю Tensorflow\"\n",
    "\n",
    "$\\Rightarrow rank\\_q_i^{'} = 2$\n",
    "\n",
    "Вычислим метрику *Hits@K* для *K = 1, 4*:\n",
    "\n",
    "- [K = 1] $\\text{Hits@1} =  [rank\\_q_i^{'} \\le 1)] = 0$\n",
    "- [K = 4] $\\text{Hits@4} =  [rank\\_q_i^{'} \\le 4] = 1$\n",
    "\n",
    "Вычислим метрику *DCG@K* для *K = 1, 4*:\n",
    "- [K = 1] $\\text{DCG@1} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 1] = 0$\n",
    "- [K = 4] $\\text{DCG@4} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 4] = \\frac{1}{\\log_2{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4L6HJJC6j2B",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Вычислим `DCG@10`, если $rank\\_q_i^{'} = 9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "K = 10\n",
    "rank_q = 9\n",
    "\n",
    "DCG = (1 / math.log2(1 + rank_q)) * (rank_q <= K)\n",
    "round(DCG, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5xWOORI6j2F",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### HITS\\_COUNT и DCG\\_SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1q9WQOx6j2H",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Каждая функция имеет два аргумента: $dup\\_ranks$ и $k$. $dup\\_ranks$ является списком, который содержит рейтинги дубликатов(их позиции в ранжированном списке). Например, $dup\\_ranks = [2]$ для примера, описанного выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "F5VwySUB6j2J",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def hits_count(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list индексов дубликатов\n",
    "        result: вернуть  Hits@k\n",
    "    \"\"\"\n",
    "    hits_value = 0\n",
    "    \n",
    "    for rank in dup_ranks:\n",
    "        hits_value += (rank <= k)\n",
    "            \n",
    "    return hits_value / len(dup_ranks)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "82hQaxCH6j2R",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dcg_score(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list индексов дубликатов\n",
    "        result: вернуть DCG@k\n",
    "    \"\"\"\n",
    "    dcg_value = 0\n",
    "    \n",
    "    for rank in dup_ranks:\n",
    "        dcg_value += (1 / math.log2(1 + rank)) * (rank <= k)\n",
    "        \n",
    "    return dcg_value / len(dup_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcwHeXN26j2Y",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Протестируем функции. Пусть $N = 1$, то есть один эксперимент. Будем искать копию вопроса и оценивать метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "fjISmOEW6j2h",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gLa_Wqfh6j2m",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваш ответ HIT: [0.0, 1.0, 1.0, 1.0]\n",
      "Ваш ответ DCG: [0.0, 0.63093, 0.63093, 0.63093]\n"
     ]
    }
   ],
   "source": [
    "copy_answers = [\"How does the catch keyword determine the type of exception that was thrown\",]\n",
    "\n",
    "# наши кандидаты\n",
    "candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\",\n",
    "                       \"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                       \"NSLog array description not memory address\",\n",
    "                       \"PECL_HTTP not recognised php ubuntu\"],]\n",
    "\n",
    "# dup_ranks — позиции наших копий, так как эксперимент один, то этот массив длины 1\n",
    "dup_ranks = [2]\n",
    "\n",
    "# вычисляем метрику для разных k\n",
    "print('Ваш ответ HIT:', [hits_count(dup_ranks, k) for k in range(1, 5)])\n",
    "print('Ваш ответ DCG:', [round(dcg_score(dup_ranks, k), 5) for k in range(1, 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "B0NFWq4f6j2u",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HITS</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCG</th>\n",
       "      <td>0</td>\n",
       "      <td>0.63093</td>\n",
       "      <td>0.63093</td>\n",
       "      <td>0.63093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1        2        3        4\n",
       "HITS  0  1.00000  1.00000  1.00000\n",
       "DCG   0  0.63093  0.63093  0.63093"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correct_answers - метрика для разных k\n",
    "correct_answers = pd.DataFrame([[0, 1, 1, 1], [0, 1 / (np.log2(3)), 1 / (np.log2(3)), 1 / (np.log2(3))]],\n",
    "                               index=['HITS', 'DCG'], columns=range(1,5))\n",
    "correct_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHZqgDTo6j0i",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Данные\n",
    "[arxiv link](https://drive.google.com/file/d/1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_/edit)\n",
    "\n",
    "`train.tsv` - выборка для обучения.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>**\n",
    "\n",
    "`validation.tsv` - тестовая выборка.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>, <отрицательный пример 1>, <отрицательный пример 2>, ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1628256058346,
     "user": {
      "displayName": "Deep Learning School",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhNf0RkP5WvkU5MixKfC1Sv3mb-9QWgAbC6VcfQvA=s64",
      "userId": "16549096980415837553"
     },
     "user_tz": -180
    },
    "id": "jKVK2lDGvrIe",
    "outputId": "51944c9b-d6e8-41af-bec4-bb35fba5d51b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!unzip stackoverflow_similar_questions.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hil2UsUG6j22",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Считаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    data = []\n",
    "    for line in open(filename, encoding='utf-8'):\n",
    "        data.append(list(line.rstrip().split('\\t')))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkTxY3Mk9_nG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Нам понадобиться только файл validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "error",
     "timestamp": 1628256058355,
     "user": {
      "displayName": "Deep Learning School",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhNf0RkP5WvkU5MixKfC1Sv3mb-9QWgAbC6VcfQvA=s64",
      "userId": "16549096980415837553"
     },
     "user_tz": -180
    },
    "id": "PTVB9Tnp6j29",
    "outputId": "9c55c802-3d82-471d-eab2-195dabf5026c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "validation_data = read_corpus('./stackoverflow_similar_questions/data/validation.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTHfL-9y6j3F",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Кол-во строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "z6ubXhIe6j3H",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3760"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaOQblBy6j3M",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Размер нескольких первых строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "yRx6e-Pe6j3M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1001\n",
      "2 1001\n",
      "3 1001\n",
      "4 1001\n",
      "5 1001\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i + 1, len(validation_data[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySQQp0oQt1Ep",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ранжирование без обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iElEDhj-6j3R",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Функция ранжирования кандидатов на основе косинусного расстояния. Функция должна по списку кандидатов вернуть отсортированный список пар (позиция в исходном списке кандидатов, кандидат). При этом позиция кандидата в полученном списке является его рейтингом (первый - лучший). Например, если исходный список кандидатов был [a, b, c], и самый похожий на исходный вопрос среди них - c, затем a, и в конце b, то функция должна вернуть список **[(2, c), (0, a), (1, b)]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "K02JARKr6j3T",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1yP8wJWj6j3X",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rank_candidates(question, candidates, embeddings, tokenizer, dim=200):\n",
    "    \"\"\"\n",
    "        question: строка\n",
    "        candidates: массив строк(кандидатов) [a, b, c]\n",
    "        embeddings: наше векторное представление\n",
    "        tokenizer: токенайзер\n",
    "        dim: размер любого вектора в нашем представлении\n",
    "        result: пары (начальная позиция, кандидат) [(2, c), (0, a), (1, b)]\n",
    "    \"\"\"\n",
    "    zeros = 0\n",
    "    temp_list = []\n",
    "    q_vector = question_to_vec(question, embeddings, tokenizer)\n",
    "    \n",
    "    if q_vector.all() == 0:  # определим, является ли вектор вопроса нулевым\n",
    "        zeros += 1\n",
    "    \n",
    "    for i, candidate in enumerate(candidates):\n",
    "        c_vector = question_to_vec(candidate, embeddings, tokenizer)\n",
    "        measure = cosine_similarity(q_vector.reshape(1, -1), c_vector.reshape(1, -1))\n",
    "        temp_list.append((i, candidate, measure[0][0]))\n",
    "    \n",
    "    temp_list.sort(key=lambda x: x[2], reverse=True)  # отсортируем по косинусному расстоянию\n",
    "    result = [(str(i), candidate) for i, candidate, measure in temp_list]  \n",
    "    \n",
    "    return zeros, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnBszTb76j3c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Протестируем работу функции на примерах ниже. Пусть $N=2$, то есть два эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "xvQgtP176j3h",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "questions = ['converting string to list', 'Sending array via Ajax fails'] \n",
    "\n",
    "candidates = [['Convert Google results object (pure js) to Python object', # первый эксперимент\n",
    "               'C# create cookie from string and send it',\n",
    "               'How to use jQuery AJAX for an outside domain?'],\n",
    "              \n",
    "              ['Getting all list items of an unordered list in PHP',      # второй эксперимент\n",
    "               'WPF- How to update the changes in list item of a list',\n",
    "               'select2 not displaying search results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "bPj1JGFi6j3m",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эксперимент 1, RE_tokenizer\n",
      "Всего 0 нулевых векторов в вопросах\n",
      "[('1', 'C# create cookie from string and send it'), ('0', 'Convert Google results object (pure js) to Python object'), ('2', 'How to use jQuery AJAX for an outside domain?')]\n",
      "\n",
      "Эксперимент 2, RE_tokenizer\n",
      "Всего 0 нулевых векторов в вопросах\n",
      "[('0', 'Getting all list items of an unordered list in PHP'), ('2', 'select2 not displaying search results'), ('1', 'WPF- How to update the changes in list item of a list')]\n",
      "\n",
      "Эксперимент 1, WP_tokenizer\n",
      "Всего 0 нулевых векторов в вопросах\n",
      "[('1', 'C# create cookie from string and send it'), ('0', 'Convert Google results object (pure js) to Python object'), ('2', 'How to use jQuery AJAX for an outside domain?')]\n",
      "\n",
      "Эксперимент 2, WP_tokenizer\n",
      "Всего 0 нулевых векторов в вопросах\n",
      "[('0', 'Getting all list items of an unordered list in PHP'), ('2', 'select2 not displaying search results'), ('1', 'WPF- How to update the changes in list item of a list')]\n",
      "\n",
      "Эксперимент 1, Spacy_tokenizer\n",
      "Всего 0 нулевых векторов в вопросах\n",
      "[('1', 'C# create cookie from string and send it'), ('0', 'Convert Google results object (pure js) to Python object'), ('2', 'How to use jQuery AJAX for an outside domain?')]\n",
      "\n",
      "Эксперимент 2, Spacy_tokenizer\n",
      "Всего 0 нулевых векторов в вопросах\n",
      "[('0', 'Getting all list items of an unordered list in PHP'), ('2', 'select2 not displaying search results'), ('1', 'WPF- How to update the changes in list item of a list')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, tokenizer in tokenizers.items():\n",
    "    for question, q_candidates, i in zip(questions, candidates, range(2)):\n",
    "        zeros, ranks = rank_candidates(question, q_candidates, wv_embeddings, tokenizer)\n",
    "        print(f'Эксперимент {i+1}, {name}')\n",
    "        print(f'Всего {zeros} нулевых векторов в вопросах')\n",
    "        print(ranks)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Все токенайзеры показали одинаковый результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1ttnIBe6j3x",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Последовательность начальных индексов `для эксперимента 1`  1, 0, 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последовательность начальных индексов `для эксперимента 2`  0, 2, 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPllOY-Y6j30",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь мы можем оценить качество нашего метода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "nu7K4mis6j32",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1000/3760 [04:36<12:42,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE_tokenizer\n",
      "Всего было 0 нулевых векторов в вопросах\n",
      "DCG@   1: 0.415 | Hits@   1: 0.415\n",
      "DCG@   5: 0.502 | Hits@   5: 0.582\n",
      "DCG@  10: 0.525 | Hits@  10: 0.651\n",
      "DCG@ 100: 0.570 | Hits@ 100: 0.874\n",
      "DCG@ 500: 0.583 | Hits@ 500: 0.973\n",
      "DCG@1000: 0.586 | Hits@1000: 1.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1000/3760 [04:35<12:41,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WP_tokenizer\n",
      "Всего было 0 нулевых векторов в вопросах\n",
      "DCG@   1: 0.410 | Hits@   1: 0.410\n",
      "DCG@   5: 0.500 | Hits@   5: 0.580\n",
      "DCG@  10: 0.521 | Hits@  10: 0.645\n",
      "DCG@ 100: 0.568 | Hits@ 100: 0.875\n",
      "DCG@ 500: 0.581 | Hits@ 500: 0.973\n",
      "DCG@1000: 0.583 | Hits@1000: 1.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1000/3760 [1:42:11<4:42:03,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy_tokenizer\n",
      "Всего было 3 нулевых векторов в вопросах\n",
      "DCG@   1: 0.392 | Hits@   1: 0.392\n",
      "DCG@   5: 0.482 | Hits@   5: 0.561\n",
      "DCG@  10: 0.503 | Hits@  10: 0.627\n",
      "DCG@ 100: 0.549 | Hits@ 100: 0.850\n",
      "DCG@ 500: 0.565 | Hits@ 500: 0.967\n",
      "DCG@1000: 0.568 | Hits@1000: 1.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, tokenizer in tokenizers.items():\n",
    "    sum_zero = 0\n",
    "    wv_ranking = []\n",
    "    max_validation_examples = 1000\n",
    "    for i, line in enumerate(tqdm(validation_data)):\n",
    "        if i == max_validation_examples:\n",
    "            break\n",
    "        q, *ex = line\n",
    "        zeros, ranks = rank_candidates(q, ex, wv_embeddings, tokenizer)\n",
    "        sum_zero += zeros\n",
    "        wv_ranking.append([r[0] for r in ranks].index('0') + 1)\n",
    "    print(name)\n",
    "    print(f'Всего было {sum_zero} нулевых векторов в вопросах')\n",
    "    for k in [1, 5, 10, 100, 500, 1000]:\n",
    "        print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Наибольшую точность на `предобученных` эмбеддингах показал токенайзер `на основе регулярных выражений`. Чуть меньшую точность показал `WordPunkt` токенайзер, но в связи с тем, что в предобученных эмбеддингах очень мало знаков пунктуации, то разница от первого токенайзера минимальная. Неожиданно низкий результат показал токенайзер `Spacy` с лемматизацией. Не смотря на то, что в предобученных векторных представления присутствуют различные формы слова. Видимо в этой задаче нормализация не приносит пользу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL6_Rjg3InL8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Эмбеддинги, обученные на корпусе похожих вопросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr281ZyEJfjT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Улучшим качество модели.<br>Склеим вопросы в пары и обучим на них модель Word2Vec из gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*В данной задаче размер окна будет подобран с помощью `GridSearch`, но обычно для коротких текстов берут `window_size` около `10` чтобы получить больше информации.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "iNvbpR5gJIPz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = read_corpus('./stackoverflow_similar_questions/data/train.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Количество строк:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Выведем несколько строк датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['converting string to list', 'Convert Google results object (pure js) to Python object']\n",
      "\n",
      "['Which HTML 5 Canvas Javascript to use for making an interactive drawing tool?', 'Event handling for geometries in Three.js?']\n",
      "\n",
      "['Sending array via Ajax fails', 'Getting all list items of an unordered list in PHP']\n",
      "\n",
      "['How to insert CookieCollection to CookieContainer?', 'C# create cookie from string and send it']\n",
      "\n",
      "['Updating one element of a bound Observable collection', 'WPF- How to update the changes in list item of a list']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(train_data[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Эмбеддинги без нормализации (лемматизации)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Подготовим препроцессинг данных для обучения эмбеддингов. Используем слова в нижнем регистре, со знаками пунктуации и без использования нормализации. Кроме того, отфильтруем слова согласно стоп-листа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "def preproc_nltk(text):\n",
    "#     text = re.sub('[^A-z]', ' ', text)\n",
    "    return ' '.join([word for word in word_tokenize(text.lower()) if word not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [03:05<00:00, 5376.81it/s]\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for questions in tqdm(train_data):\n",
    "    question = ' '.join(q for q in questions)\n",
    "    words.append(preproc_nltk(question).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Выведем несколько строк подготовленного датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['converting', 'string', 'list', 'convert', 'google', 'results', 'object', '(', 'pure', 'js', ')', 'python', 'object']\n",
      "\n",
      "['html', '5', 'canvas', 'javascript', 'use', 'making', 'interactive', 'drawing', 'tool', '?', 'event', 'handling', 'geometries', 'three.js', '?']\n",
      "\n",
      "['sending', 'array', 'via', 'ajax', 'fails', 'getting', 'list', 'items', 'unordered', 'list', 'php']\n",
      "\n",
      "['insert', 'cookiecollection', 'cookiecontainer', '?', 'c', '#', 'create', 'cookie', 'string', 'send']\n",
      "\n",
      "['updating', 'one', 'element', 'bound', 'observable', 'collection', 'wpf-', 'update', 'changes', 'list', 'item', 'list']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(words[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Подберём оптимальные параметры `min_count` и `windows` на примере `re_tokenizer` и алгоритме `CBOW`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [8:19:58<00:00, 2999.85s/it] \n"
     ]
    }
   ],
   "source": [
    "gs_1 = []\n",
    "for count in tqdm(range(1, 11)):\n",
    "    for window in range(1, 11):\n",
    "        embeddings_trained = Word2Vec(words,    # data for model to train on\n",
    "                              vector_size=200,  # embedding vector size\n",
    "                              min_count=count,  # consider words that occured at least 3 times\n",
    "                              window=window,    # windows size\n",
    "                              workers=8,        # num workers\n",
    "                              sg=0).wv          # algorithm\n",
    "        \n",
    "        wv_ranking = []\n",
    "        max_validation_examples = 1000\n",
    "        for i, line in enumerate(validation_data):\n",
    "            if i == max_validation_examples:\n",
    "                break\n",
    "            q, *ex = line\n",
    "            _, ranks = rank_candidates(q, ex, embeddings_trained, re_tokenizer)\n",
    "            wv_ranking.append([r[0] for r in ranks].index('0') + 1)\n",
    "        for k in [1, 5, 10, 100, 500, 1000]:\n",
    "            gs_1.append((count, window, k, dcg_score(wv_ranking, k), hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(result):\n",
    "    best_count, best_window, best_score = 0, 0, 0\n",
    "    \n",
    "    for res in result:\n",
    "        num_count, num_window, k, dcg, hits = res\n",
    "        if k==1 and hits > best_score:\n",
    "            best_score = hits\n",
    "            best_count = num_count\n",
    "            best_window = num_window\n",
    "    print(f\"Лучший результат: Hits@1 = {best_score} при min_count = {best_count} и window = {best_window}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший результат: Hits@1 = 0.427 при min_count = 7 и window = 10\n"
     ]
    }
   ],
   "source": [
    "get_metrics(gs_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Выполним аналогичный подбор параметров на втором алгоритме `skip-gram`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:28:14<00:00, 3769.50s/it] \n"
     ]
    }
   ],
   "source": [
    "gs_2 = []\n",
    "for count in tqdm(range(1, 11)):\n",
    "    for window in range(1, 11):\n",
    "        embeddings_trained = Word2Vec(words,    # data for model to train on\n",
    "                              vector_size=200,  # embedding vector size\n",
    "                              min_count=count,  # consider words that occured at least 3 times\n",
    "                              window=window,    # windows size\n",
    "                              workers=8,        # num workers\n",
    "                              sg=1).wv          # algorithm\n",
    "        \n",
    "        wv_ranking = []\n",
    "        max_validation_examples = 1000\n",
    "        for i, line in enumerate(validation_data):\n",
    "            if i == max_validation_examples:\n",
    "                break\n",
    "            q, *ex = line\n",
    "            _, ranks = rank_candidates(q, ex, embeddings_trained, re_tokenizer)\n",
    "            wv_ranking.append([r[0] for r in ranks].index('0') + 1)\n",
    "        for k in [1, 5, 10, 100, 500, 1000]:\n",
    "            gs_2.append((count, window, k, dcg_score(wv_ranking, k), hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший результат: Hits@1 = 0.539 при min_count = 5 и window = 10\n"
     ]
    }
   ],
   "source": [
    "get_metrics(gs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Максимальная точность была достигнута при параметрах `min_count=5`, `window_size=10` и алгоритме `skip-gram`. Вероятно не стоит брать значение `min_count > 5` так как в этом случае в векторных представления будет значительно меньше слов. При `window_size > 10` окно по размерам будет приближаться к общей длине текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Используя полученные оптимальные параметры, проверим качество ранжирования для каждого из трёх токенайзеров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_trained = Word2Vec(words,            # data for model to train on\n",
    "                              vector_size=200,  # embedding vector size\n",
    "                              min_count=5,      # consider words that occured at least 3 times\n",
    "                              window=10,        # windows size\n",
    "                              workers=8,        # num workers\n",
    "                              sg=1).wv          # algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1000/3760 [04:25<12:13,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE_tokenizer\n",
      "Всего было 0 нулевых векторов в вопросах\n",
      "DCG@   1: 0.536 | Hits@   1: 0.536\n",
      "DCG@   5: 0.617 | Hits@   5: 0.687\n",
      "DCG@  10: 0.640 | Hits@  10: 0.758\n",
      "DCG@ 100: 0.674 | Hits@ 100: 0.914\n",
      "DCG@ 500: 0.683 | Hits@ 500: 0.989\n",
      "DCG@1000: 0.684 | Hits@1000: 1.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1000/3760 [04:28<12:22,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WP_tokenizer\n",
      "Всего было 0 нулевых векторов в вопросах\n",
      "DCG@   1: 0.517 | Hits@   1: 0.517\n",
      "DCG@   5: 0.601 | Hits@   5: 0.676\n",
      "DCG@  10: 0.621 | Hits@  10: 0.737\n",
      "DCG@ 100: 0.656 | Hits@ 100: 0.902\n",
      "DCG@ 500: 0.666 | Hits@ 500: 0.979\n",
      "DCG@1000: 0.668 | Hits@1000: 1.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1000/3760 [1:34:05<4:19:42,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy_tokenizer\n",
      "Всего было 1 нулевых векторов в вопросах\n",
      "DCG@   1: 0.510 | Hits@   1: 0.510\n",
      "DCG@   5: 0.593 | Hits@   5: 0.665\n",
      "DCG@  10: 0.615 | Hits@  10: 0.734\n",
      "DCG@ 100: 0.649 | Hits@ 100: 0.893\n",
      "DCG@ 500: 0.659 | Hits@ 500: 0.974\n",
      "DCG@1000: 0.662 | Hits@1000: 1.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, tokenizer in tokenizers.items():\n",
    "    sum_zero = 0\n",
    "    wv_ranking = []\n",
    "    max_validation_examples = 1000\n",
    "    for i, line in enumerate(tqdm(validation_data)):\n",
    "        if i == max_validation_examples:\n",
    "            break\n",
    "        q, *ex = line\n",
    "        zeros, ranks = rank_candidates(q, ex, embeddings_trained, tokenizer)\n",
    "        sum_zero += zeros\n",
    "        wv_ranking.append([r[0] for r in ranks].index('0') + 1)\n",
    "    print(name)\n",
    "    print(f'Всего было {sum_zero} нулевых векторов в вопросах')\n",
    "    for k in [1, 5, 10, 100, 500, 1000]:\n",
    "        print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Эмбеддинги с нормализацией (лемматизацией)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Подготовим препроцессинг данных для обучения эмбеддингов c лемматизацией. Также используем слова в нижнем регистре, со знаками пунктуации, отфильтруем слова согласно стоп-листа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preproc_nltk_lemma(text):\n",
    "    text = ' '.join([word for word in word_tokenize(text.lower()) if word not in stopWords])\n",
    "    return spacy_tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [1:51:09<00:00, 149.93it/s]\n"
     ]
    }
   ],
   "source": [
    "words_lemma = []\n",
    "for questions in tqdm(train_data):\n",
    "    question = ' '.join(q for q in questions)\n",
    "    words_lemma.append(preproc_nltk_lemma(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Выведем несколько строк подготовленного датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['convert', 'string', 'list', 'convert', 'google', 'result', 'object', '(', 'pure', 'js', ')', 'python', 'object']\n",
      "\n",
      "['html', '5', 'canvas', 'javascript', 'use', 'make', 'interactive', 'drawing', 'tool', '?', 'event', 'handling', 'geometry', 'three.js', '?']\n",
      "\n",
      "['send', 'array', 'via', 'ajax', 'fail', 'get', 'list', 'item', 'unordered', 'list', 'php']\n",
      "\n",
      "['insert', 'cookiecollection', 'cookiecontainer', '?', 'c', '#', 'create', 'cookie', 'string', 'send']\n",
      "\n",
      "['update', 'one', 'element', 'bind', 'observable', 'collection', 'wpf-', 'update', 'change', 'list', 'item', 'list']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(words_lemma[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Обучим эмбеддинги с нормализацией на полученных ранее оптимальных параметрах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_trained_lemma = Word2Vec(words_lemma,  # data for model to train on\n",
    "                           vector_size=200,       # embedding vector size\n",
    "                           min_count=5,           # consider words that occured at least 3 times\n",
    "                           window=10,             # windows size\n",
    "                           workers=8,             # num workers\n",
    "                           sg=1).wv               # algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Проверим качество ранжирования для каждого из трёх токенайзеров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1000/3760 [04:37<12:44,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE_tokenizer\n",
      "Всего было 1 нулевых векторов в вопросах\n",
      "DCG@   1: 0.359 | Hits@   1: 0.359\n",
      "DCG@   5: 0.438 | Hits@   5: 0.504\n",
      "DCG@  10: 0.457 | Hits@  10: 0.565\n",
      "DCG@ 100: 0.499 | Hits@ 100: 0.771\n",
      "DCG@ 500: 0.520 | Hits@ 500: 0.938\n",
      "DCG@1000: 0.527 | Hits@1000: 1.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1000/3760 [04:37<12:46,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WP_tokenizer\n",
      "Всего было 1 нулевых векторов в вопросах\n",
      "DCG@   1: 0.349 | Hits@   1: 0.349\n",
      "DCG@   5: 0.425 | Hits@   5: 0.491\n",
      "DCG@  10: 0.446 | Hits@  10: 0.555\n",
      "DCG@ 100: 0.486 | Hits@ 100: 0.754\n",
      "DCG@ 500: 0.509 | Hits@ 500: 0.936\n",
      "DCG@1000: 0.516 | Hits@1000: 1.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1000/3760 [1:39:44<4:35:17,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy_tokenizer\n",
      "Всего было 0 нулевых векторов в вопросах\n",
      "DCG@   1: 0.378 | Hits@   1: 0.378\n",
      "DCG@   5: 0.457 | Hits@   5: 0.526\n",
      "DCG@  10: 0.476 | Hits@  10: 0.586\n",
      "DCG@ 100: 0.515 | Hits@ 100: 0.782\n",
      "DCG@ 500: 0.536 | Hits@ 500: 0.943\n",
      "DCG@1000: 0.542 | Hits@1000: 1.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, tokenizer in tokenizers.items():\n",
    "    sum_zero = 0\n",
    "    wv_ranking = []\n",
    "    max_validation_examples = 1000\n",
    "    for i, line in enumerate(tqdm(validation_data)):\n",
    "        if i == max_validation_examples:\n",
    "            break\n",
    "        q, *ex = line\n",
    "        zeros, ranks = rank_candidates(q, ex, embeddings_trained_lemma, tokenizer)\n",
    "        sum_zero += zeros\n",
    "        wv_ranking.append([r[0] for r in ranks].index('0') + 1)\n",
    "    print(name)\n",
    "    print(f'Всего было {sum_zero} нулевых векторов в вопросах')\n",
    "    for k in [1, 5, 10, 100, 500, 1000]:\n",
    "        print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vymVj8IxO2PO",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Во всех проведённых экспериментах наилучшее качество показал токенайзер на `основе регулярных выражений` (`RE tokenizer`), чуть хуже показал себя `WordPunkt` токенайзер с токенизацией знаков пунктуации и на последнем месте `Spacy`, который дополнительно проводит нормализацию (лемматизацию) слов. Такие результаты я связываю с особенностями исходного корпуса. Для вопросов и ответов на StackOverFlow не так важны знаки препинания (это не художественный текст) и формы слов, сколько семантика. Данный тип текстов скорее технические диалоги в виде свободной формы общения, которые могут позволять себе некоторые вольности. Поэтому обычный токенайзер без учёта пунктуации и лемматизации показал в данной задаче наилучшее качество. Конечно, на другом корпусе (например на корпусе текстов художественной литературы) результат может быть полностью противоположный. Кроме того, токенизация с лемматизацией позволяет снизить размер словаря, но в данной задаче это не помогло увеличить качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "С учётом вышесказанного, эмбеддинги без нормализации показали себя лучше чем эмбеддинги созданные с предварительной нормализацией (лемматизацией) слов. Если сравнить предобученные эмбеддинги с обученными, то последние показали точность выше как на `cbow` так и, особенно, на `skip-gram` не смотря почти на вдвое меньший объём векторного пространства. Я связываю это с подбором оптимальных параметров `window` и `min_count` для текущнй задачи, что позволило увеличить итоговую точность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Итоговый результат получился не очень впечатляющий (максимальная точность `DCG@1: 0.536`, `Hits@1: 0.536`). Вероятно это связано с тем, что `Word2Vec` подход достаточно устаревший и имеет ряд существенных недостатков, таких как - отсутствие информации о предложении или контексте, в котором используется слово; не учитывается совместная встречаемость слов и разное значение одного и того же слова в зависимости от контекста. В качестве улучшения можно использовать, например, модель `GloVe` (Global Vectors), которая учитывает частоту встречаемость слов и опережает Word2Vec в большинстве тестов. Или библиотеку `fastText`, которая к основной модели Word2Vec добавляет модель символьных n-грамм и способна генерировать эмбеддинги и для неизвестных слов. Это не говоря уже о таких методах как реккурентные нейронные сети, трансформеры, языковые модели GPT, BERT."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BIWqBuEa6j0b",
    "uS9FwWNd5a3S",
    "MQk_rolFwT_h",
    "ai48-5vv6j1d",
    "Y60z4t6W6j16",
    "0sUSxk866j1_",
    "J5xWOORI6j2F",
    "tHZqgDTo6j0i",
    "ySQQp0oQt1Ep",
    "LL6_Rjg3InL8"
   ],
   "name": "[homework]simple_embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
